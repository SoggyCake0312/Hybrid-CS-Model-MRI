{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W-net Model - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from keras.optimizers import  Adam\n",
    "\n",
    "\n",
    "# Importing our w-net model\n",
    "MY_UTILS_PATH = \"../Modules/\"\n",
    "if not MY_UTILS_PATH in sys.path:\n",
    "    sys.path.append(MY_UTILS_PATH)\n",
    "import frequency_spatial_network as fsnet\n",
    "\n",
    "# Importing callbacks and data augmentation utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Set \n",
    "train_path = r\"../../calgary/Train/Train/*.npy\"\n",
    "# train_path = r\"D:\\Dataset\\calgary\\Train_Temp\\*.npy\"\n",
    "kspace_files_train = np.asarray(glob.glob(train_path))\n",
    "\n",
    "# Validation set\n",
    "val_path = r\"../../calgary/Val/Val/*.npy\"\n",
    "kspace_files_val = np.asarray(glob.glob(val_path))\n",
    "\n",
    "indexes = np.arange(kspace_files_train.size,dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "kspace_files_train = kspace_files_train[indexes]\n",
    "\n",
    "\n",
    "print(kspace_files_train[-1])\n",
    "print(len(kspace_files_train))\n",
    "\n",
    "print(kspace_files_val[-1])\n",
    "print(len(kspace_files_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_rate = '20'\n",
    "imshape = (256,256)\n",
    "norm = np.sqrt(imshape[0]*imshape[1])\n",
    "nchannels = 2 #complex data real + imag\n",
    "\n",
    "# undersampling patterns - uncentred k-space\n",
    "var_sampling_mask = np.load(\"../Data/sampling_mask_\" + under_rate + \"perc.npy\")\n",
    "\n",
    "print(\"Undersampling:\", 1.0*var_sampling_mask.sum()/var_sampling_mask.size)\n",
    "print(\"Mask type:\",  var_sampling_mask.dtype)\n",
    "plt.figure()\n",
    "plt.imshow(~var_sampling_mask,cmap = \"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of samples\n",
    "ntrain = 0\n",
    "for ii in range(len(kspace_files_train)):\n",
    "    ntrain += np.load(kspace_files_train[ii]).shape[0]\n",
    "\n",
    "# Load train data    \n",
    "rec_train = np.zeros((ntrain,imshape[0],imshape[1],2))\n",
    "kspace_train = np.zeros((ntrain,imshape[0],imshape[1],2))\n",
    "aux_counter = 0\n",
    "for ii in range(len(kspace_files_train)):\n",
    "    aux_kspace = np.load(kspace_files_train[ii])/norm\n",
    "    aux = aux_kspace.shape[0]   \n",
    "    aux2 = np.fft.ifft2(aux_kspace[:,:,:,0]+1j*aux_kspace[:,:,:,1])\n",
    "    rec_train[aux_counter:aux_counter+aux,:,:,0] = aux2.real\n",
    "    rec_train[aux_counter:aux_counter+aux,:,:,1] = aux2.imag\n",
    "    kspace_train[aux_counter:aux_counter+aux,:,:,0] = aux_kspace[:,:,:,0]\n",
    "    kspace_train[aux_counter:aux_counter+aux,:,:,1] = aux_kspace[:,:,:,1]\n",
    "    aux_counter+=aux\n",
    "\n",
    "# Shuffle training    \n",
    "indexes = np.arange(rec_train.shape[0],dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "rec_train = rec_train[indexes]\n",
    "\n",
    "kspace_train[:,var_sampling_mask,:] = 0 # undersample k-space\n",
    "\n",
    "# save k-space and image domain stats\n",
    "stats = np.zeros(4)\n",
    "stats[0] = kspace_train.mean()\n",
    "stats[1] = kspace_train.std()\n",
    "aux = np.abs(rec_train[:,:,:,0] +1j*rec_train[:,:,:,1])\n",
    "stats[2] = aux.mean()\n",
    "stats[3] = aux.std()\n",
    "np.save(\"../Data/stats_fs_unet_norm_\" + under_rate + \".npy\",stats)\n",
    "\n",
    "print(\"Number of training samples\", rec_train.shape[0])\n",
    "kspace_train = 0 # release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of samples\n",
    "nval = 0\n",
    "for ii in range(len(kspace_files_val)):\n",
    "    nval += np.load(kspace_files_val[ii]).shape[0]\n",
    "\n",
    "kspace_val = np.zeros((nval,imshape[0],imshape[1],nchannels))\n",
    "rec_val = np.zeros((nval,imshape[0],imshape[1],1))\n",
    "aux_counter = 0\n",
    "for ii in range(len(kspace_files_val)):\n",
    "    aux_kspace = np.load(kspace_files_val[ii])/norm\n",
    "    aux = aux_kspace.shape[0]   \n",
    "    kspace_val[aux_counter:aux_counter+aux] = aux_kspace\n",
    "    rec_val[aux_counter:aux_counter+aux,:,:,0] = \\\n",
    "    np.abs(np.fft.ifft2(aux_kspace[:,:,:,0]+1j*aux_kspace[:,:,:,1]))\n",
    "    aux_counter+=aux\n",
    "\n",
    "# Undersampling kspace\n",
    "kspace_val2 = kspace_val.copy()\n",
    "kspace_val[:,var_sampling_mask,:] = 0\n",
    "kspace_val = (kspace_val-stats[0])/stats[1]\n",
    "\n",
    "print(\"Number of samples\", kspace_val.shape[0])\n",
    "print(\"Kspace under stats\", kspace_val.mean(),kspace_val.std())\n",
    "print(\"Kspace full stats\", kspace_val2.mean(),kspace_val2.std())\n",
    "print(\"Rec stats\", rec_val.mean(),rec_val.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "batch_size= 16\n",
    "model = fsnet.wnet(stats[0],stats[1],stats[2],stats[3],\\\n",
    "                                   kshape = (5,5),kshape2=(3,3))\n",
    "opt = Adam(lr=1e-3,decay = 1e-7)\n",
    "model.compile(loss = [fsnet.nrmse,fsnet.nrmse],optimizer=opt, loss_weights=[0.01, 0.99])\n",
    "\n",
    "model_name = \"../Models/wnet_\" + under_rate + \".hdf5\"\n",
    "if os.path.isfile(model_name):\n",
    "    model.load_weights(model_name)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Early stopping callback to shut down training after\n",
    "#10 epochs with no improvement\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                                       patience=20, \n",
    "                                       verbose=0, mode='min')\n",
    "\n",
    "# Checkpoint callback to save model  along the epochs\n",
    "checkpoint = ModelCheckpoint(model_name, mode = 'min', \\\n",
    "                             monitor='val_loss',verbose=0,\\\n",
    "                             save_best_only=True, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 905\n",
    "image_datagen1 = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.075,\n",
    "        height_shift_range=0.075,\n",
    "        shear_range=0.25,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "image_datagen2 = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.075,\n",
    "        height_shift_range=0.075,\n",
    "        shear_range=0.25,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "image_datagen1.fit(rec_train[:,:,:,0,np.newaxis], augment=True, seed=seed)\n",
    "image_datagen2.fit(rec_train[:,:,:,1,np.newaxis], augment=True, seed=seed)\n",
    "\n",
    "image_generator1 = image_datagen1.flow(rec_train[:,:,:,0,np.newaxis],batch_size = batch_size,seed = seed)\n",
    "image_generator2 = image_datagen1.flow(rec_train[:,:,:,1,np.newaxis],batch_size = batch_size,seed = seed)\n",
    "\n",
    "def combine_generator(gen1,gen2,under_mask,stats):\n",
    "    while True:\n",
    "        rec_real = gen1.next()\n",
    "        rec_imag = gen2.next()\n",
    "        kspace = np.fft.fft2(rec_real[:,:,:,0]+1j*rec_imag[:,:,:,0])\n",
    "        kspace2 = np.zeros((kspace.shape[0],kspace.shape[1],kspace.shape[2],2))\n",
    "        kspace2[:,:,:,0] = kspace.real\n",
    "        kspace2[:,:,:,1] = kspace.imag\n",
    "        kspace_under = kspace2.copy()\n",
    "        kspace_under[:,var_sampling_mask,:] = 0\n",
    "        kspace_under = (kspace_under-stats[0])/stats[1]\n",
    "        rec = np.abs(rec_real[:,:,:,0]+1j*rec_imag[:,:,:,0])[:,:,:,np.newaxis]\n",
    "        yield(kspace_under, [kspace2,rec])\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "combined = combine_generator(image_generator1,image_generator2, var_sampling_mask,stats)\n",
    "\n",
    "\n",
    "# sample data augmentation\n",
    "for ii in combined:\n",
    "    print(ii[1][1].shape)\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(ii[1][1][10,:,:,0],cmap = 'gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.log(1+np.abs(ii[1][0][10,:,:,0] + 1j*ii[1][0][8,:,:,1])),cmap = 'gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(combined,\n",
    "                 epochs=epochs,\n",
    "                 steps_per_epoch=rec_train.shape[0] / batch_size,\n",
    "                 verbose=1,\n",
    "                 validation_data= (kspace_val,[kspace_val2,rec_val]),\n",
    "                 callbacks=[checkpoint,earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], color='b', label='train')\n",
    "plt.plot(history.history['val_loss'], color='r', label='val')\n",
    "plt.title('Loss curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
