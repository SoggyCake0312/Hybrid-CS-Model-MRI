{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27043863",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# W-net Model - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4199d5e-7205-4549-99b5-0b43b6f05f53",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f756fa0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from keras.optimizers import  Adam\n",
    "\n",
    "\n",
    "# Importing our w-net model\n",
    "MY_UTILS_PATH = \"../Modules/\"\n",
    "if not MY_UTILS_PATH in sys.path:\n",
    "    sys.path.append(MY_UTILS_PATH)\n",
    "import frequency_spatial_network as fsnet\n",
    "\n",
    "# Importing callbacks and data augmentation utils\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c562338",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "\n",
    "print(keras.__version__)\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f41f9b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(fsnet.wnet_new(1,2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5d09d-2712-4a1b-be16-b1c00fc5da9f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "BUCKET_NAME = 'calgary_iitrpr'\n",
    "elements = client.list_blobs(BUCKET_NAME)\n",
    "files=[a.name for a in elements]\n",
    "Trains = [x for x in files if \"TrainData\" in x and \"npy\" in x]\n",
    "print(Trains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76bc0f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train Set \n",
    "train_path = r\"GCS:calgary_iitrpr/calgary/TrainData/TrainData/*.npy\"\n",
    "# train_path = r\"D:\\Dataset\\calgary\\Train\\Train\\e14141s3_P58880.7.npy\"\n",
    "# kspace_files_train = np.asarray(glob.glob(train_path))\n",
    "kspace_files_train = np.asarray([r\"gs://calgary_iitrpr/\"+x for x in files if \"TrainData\" in x and \"npy\" in x])\n",
    "\n",
    "# Validation set\n",
    "val_path = r\"gs://calgary_iitrpr/calgary/Test/Test/*.npy\"\n",
    "# val_path = r\"D:\\Dataset\\calgary\\Val\\Val\\e14351s3_P29184.7.npy\"\n",
    "kspace_files_val = np.asarray([r\"gs://calgary_iitrpr/\"+x for x in files if \"Val\" in x and \"npy\" in x])\n",
    "\n",
    "indexes = np.arange(kspace_files_train.size,dtype = int)\n",
    "np.random.shuffle(indexes)\n",
    "kspace_files_train = kspace_files_train[indexes]\n",
    "\n",
    "\n",
    "print(kspace_files_train[-1])\n",
    "print(len(kspace_files_train))\n",
    "\n",
    "print(kspace_files_val[-1])\n",
    "print(len(kspace_files_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b296eed-1d26-4c30-a8a9-99fd99b7ca6e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from tensorflow.python.lib.io import file_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a266c923",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "under_rate = '20'\n",
    "imshape = (256,256)\n",
    "norm = np.sqrt(imshape[0]*imshape[1])\n",
    "nchannels = 2 #complex data real + imag\n",
    "\n",
    "# undersampling patterns - uncentred k-space\n",
    "var_sampling_mask = np.load(\"../Data/sampling_mask_\" + under_rate + \"perc.npy\")\n",
    "\n",
    "print(\"Undersampling:\", 1.0*var_sampling_mask.sum()/var_sampling_mask.size)\n",
    "print(\"Mask type:\",  var_sampling_mask.dtype)\n",
    "plt.figure()\n",
    "plt.imshow(~var_sampling_mask,cmap = \"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b221296b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492e59a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get number of samples\n",
    "ntrain = 0\n",
    "for ii in range(len(kspace_files_train)):\n",
    "    f = BytesIO(file_io.read_file_to_string(kspace_files_train[ii], binary_mode=True))\n",
    "    ntrain += np.load(f).shape[0]\n",
    "    \n",
    "    print(ntrain)\n",
    "    # ntrain += np.load(kspace_files_train[ii]).shape[0]\n",
    "#     ntrain += 168\n",
    "\n",
    "# print(ntrain)\n",
    "\n",
    "# Load train data    \n",
    "rec_train = np.zeros((ntrain,imshape[0],imshape[1],2))\n",
    "kspace_train = np.zeros((ntrain,imshape[0],imshape[1],2))\n",
    "aux_counter = 0\n",
    "for ii in range(len(kspace_files_train)):\n",
    "    f = BytesIO(file_io.read_file_to_string(kspace_files_train[ii], binary_mode=True))\n",
    "    aux_kspace = np.load(f)/norm\n",
    "    # aux_kspace = np.load(kspace_files_train[ii])/norm\n",
    "    aux = aux_kspace.shape[0]   \n",
    "    aux2 = np.fft.ifft2(aux_kspace[:,:,:,0]+1j*aux_kspace[:,:,:,1])\n",
    "    rec_train[aux_counter:aux_counter+aux,:,:,0] = aux2.real\n",
    "    rec_train[aux_counter:aux_counter+aux,:,:,1] = aux2.imag\n",
    "    kspace_train[aux_counter:aux_counter+aux,:,:,0] = aux_kspace[:,:,:,0]\n",
    "    kspace_train[aux_counter:aux_counter+aux,:,:,1] = aux_kspace[:,:,:,1]\n",
    "    \n",
    "    print(aux)\n",
    "    aux_counter+=aux\n",
    "\n",
    "# Shuffle training    \n",
    "# indexes = np.arange(rec_train.shape[0],dtype = int)\n",
    "# np.random.shuffle(indexes)\n",
    "# rec_train = rec_train[indexes]\n",
    "\n",
    "kspace_train[:,var_sampling_mask,:] = 0 # undersample k-space\n",
    "\n",
    "# save k-space and image domain stats\n",
    "stats = np.zeros(4)\n",
    "stats[0] = kspace_train.mean()\n",
    "stats[1] = kspace_train.std()\n",
    "aux = np.abs(rec_train[:,:,:,0] +1j*rec_train[:,:,:,1])\n",
    "stats[2] = aux.mean()\n",
    "stats[3] = aux.std()\n",
    "np.save(\"../Data/stats_fs_unet_norm_\" + under_rate + \".npy\",stats)\n",
    "\n",
    "print(\"Number of training samples\", rec_train.shape[0])\n",
    "kspace_train = 0 # release memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2151970a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfb4e59",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get number of samples\n",
    "nval = 0\n",
    "for ii in range(len(kspace_files_val)):\n",
    "    f = BytesIO(file_io.read_file_to_string(kspace_files_val[ii], binary_mode=True))\n",
    "    nval += np.load(f).shape[0]\n",
    "\n",
    "kspace_val = np.zeros((nval,imshape[0],imshape[1],nchannels))\n",
    "rec_val = np.zeros((nval,imshape[0],imshape[1],1))\n",
    "aux_counter = 0\n",
    "for ii in range(len(kspace_files_val)):\n",
    "    f = BytesIO(file_io.read_file_to_string(kspace_files_val[ii], binary_mode=True))\n",
    "    aux_kspace = np.load(f)/norm\n",
    "    aux = aux_kspace.shape[0]   \n",
    "    kspace_val[aux_counter:aux_counter+aux] = aux_kspace\n",
    "    rec_val[aux_counter:aux_counter+aux,:,:,0] = \\\n",
    "    np.abs(np.fft.ifft2(aux_kspace[:,:,:,0]+1j*aux_kspace[:,:,:,1]))\n",
    "    aux_counter+=aux\n",
    "\n",
    "# Undersampling kspace\n",
    "kspace_val2 = kspace_val.copy()\n",
    "kspace_val[:,var_sampling_mask,:] = 0\n",
    "\n",
    "rec_val = np.fft.ifft2(kspace_val[:,:,:,0]+1j*kspace_val[:,:,:,1])\n",
    "rec_val2 = np.fft.ifft2(kspace_val2[:,:,:,0]+1j*kspace_val2[:,:,:,1])\n",
    "rec_val = np.expand_dims(rec_val, axis=-1)\n",
    "\n",
    "kspace_val = (kspace_val-stats[0])/stats[1]\n",
    "\n",
    "print(\"Number of samples\", kspace_val.shape[0])\n",
    "print(\"Kspace under stats\", kspace_val.mean(),kspace_val.std())\n",
    "print(\"Kspace full stats\", kspace_val2.mean(),kspace_val2.std())\n",
    "print(\"Rec stats\", rec_val.mean(),rec_val.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176bcf82",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613fc3bd",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 75\n",
    "batch_size= 16 # changing batch size from 16 to 3 for data augmentation\n",
    "model = fsnet.model1()\n",
    "opt = Adam(lr=1e-3,decay = 1e-7)\n",
    "model.compile(loss = fsnet.nrmse,optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "model_name = \"../Models/wnet_part1.hdf5\"\n",
    "# model_name = r\"C:\\Users\\soggy\\Videos\\Hybrid-CS-Model-MRI\\Models\\wnet_part1.hdf5\"\n",
    "if os.path.isfile(model_name):\n",
    "    model.load_weights(model_name)\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Early stopping callback to shut down training after\n",
    "#10 epochs with no improvement\n",
    "earlyStopping = EarlyStopping(monitor='val_loss',\n",
    "                                       patience=20, \n",
    "                                       verbose=0, mode='min')\n",
    "\n",
    "# Checkpoint callback to save model  along the epochs\n",
    "checkpoint = ModelCheckpoint(model_name, mode = 'min', \\\n",
    "                             monitor='val_loss',verbose=0,\\\n",
    "                             save_best_only=True, save_weights_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce228a00",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd50585",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed = 905\n",
    "image_datagen1 = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.075,\n",
    "        height_shift_range=0.075,\n",
    "        shear_range=0.25,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "image_datagen2 = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.075,\n",
    "        height_shift_range=0.075,\n",
    "        shear_range=0.25,\n",
    "        zoom_range=0.25,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "image_datagen1.fit(rec_train[:,:,:,0,np.newaxis], augment=True, seed=seed)\n",
    "image_datagen2.fit(rec_train[:,:,:,1,np.newaxis], augment=True, seed=seed)\n",
    "\n",
    "image_generator1 = image_datagen1.flow(rec_train[:,:,:,0,np.newaxis],batch_size = batch_size,seed = seed)\n",
    "image_generator2 = image_datagen1.flow(rec_train[:,:,:,1,np.newaxis],batch_size = batch_size,seed = seed)\n",
    "\n",
    "def combine_generator(gen1,gen2,under_mask,stats):\n",
    "    while True:\n",
    "        rec_real = gen1.next()\n",
    "        rec_imag = gen2.next()\n",
    "        kspace = np.fft.fft2(rec_real[:,:,:,0]+1j*rec_imag[:,:,:,0])\n",
    "        kspace2 = np.zeros((kspace.shape[0],kspace.shape[1],kspace.shape[2],2))\n",
    "        kspace2[:,:,:,0] = kspace.real\n",
    "        kspace2[:,:,:,1] = kspace.imag\n",
    "        kspace_under = kspace2.copy()\n",
    "        kspace_under[:,var_sampling_mask,:] = 0\n",
    "        kspace_under = (kspace_under-stats[0])/stats[1]\n",
    "        rec = np.abs(rec_real[:,:,:,0]+1j*rec_imag[:,:,:,0])[:,:,:,np.newaxis]\n",
    "        \n",
    "        rec_under = np.fft.ifft2(kspace_under[:,:,:,0]+1j*kspace_under[:,:,:,1])\n",
    "        rec_under_expanded = np.expand_dims(rec_under, axis=-1)\n",
    "#         print(rec_under.shape, rec_under_expanded.shape)\n",
    "        yield(kspace_under, [kspace2])\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "combined = combine_generator(image_generator1,image_generator2, var_sampling_mask,stats)\n",
    "\n",
    "# sample data augmentation\n",
    "# for ii in combined:\n",
    "#     print(ii[1][1][1].shape)\n",
    "#     plt.figure()\n",
    "#     plt.subplot(221)\n",
    "#     plt.imshow(ii[1][1][1][:,:,0],cmap = 'gray')\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.subplot(222)\n",
    "#     plt.imshow(ii[1][1][1][:,:,0],cmap = 'gray')\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.subplot(223)\n",
    "#     plt.imshow(ii[1][1][1][:,:,0],cmap = 'gray')\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.subplot(224)\n",
    "#     plt.imshow(np.log(1+np.abs(ii[1][0][1][1,:,:,0] + 1j*ii[1][0][1][1,:,:,1])),cmap = 'gray')\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "#     print(ii[1][0].shape)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6204e767",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53bd090",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hist = model.fit_generator(combined,\n",
    "                 epochs=epochs,\n",
    "#                  steps_per_epoch=rec_train.shape[0] / batch_size,\n",
    "                 steps_per_epoch=rec_train.shape[0] / 16,\n",
    "                 verbose=1,\n",
    "                 validation_data= (kspace_val,[kspace_val2]),\n",
    "                 callbacks=[checkpoint,earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbb0236",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb7110f-4abb-4901-b3d4-e44d564f4642",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict = hist.history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(dict['loss'], color='b', label='train')\n",
    "plt.plot(dict['val_loss'], color='r', label='val')\n",
    "plt.title('Loss curves')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d648778",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.save(r\"C:\\Users\\soggy\\Videos\\Hybrid-CS-Model-MRI\\Models\\wnet_part1.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Local)",
   "language": "python",
   "name": "local-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2.421765,
   "end_time": "2022-11-25T13:11:05.400513",
   "environment_variables": {},
   "exception": null,
   "input_path": "train-12-11-part1.ipynb",
   "output_path": "gcptest.ipynb",
   "parameters": {},
   "start_time": "2022-11-25T13:11:02.978748",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}